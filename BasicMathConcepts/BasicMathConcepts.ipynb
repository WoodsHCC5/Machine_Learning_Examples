{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3de06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([1.0,2.5,-3.3])\n",
    "b = 4\n",
    "x = np.array([10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41619bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.0\n"
     ]
    }
   ],
   "source": [
    "f = w[0] * x[0] + w[1] * x[1] + w[2] * x[2] + b\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e32339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.0\n"
     ]
    }
   ],
   "source": [
    "f = np.dot(w, x) + b\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79393006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.0\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "n = 3\n",
    "for j in range(0,n):\n",
    "    f = f + w[j] * x[j]\n",
    "f = f + b\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4cf0c",
   "metadata": {},
   "source": [
    "# Calculating Derivatives in Python\n",
    "\n",
    "There are several ways to calculate derivatives in Python:\n",
    "\n",
    "1. **Symbolic differentiation** - Using SymPy for exact symbolic derivatives\n",
    "2. **Numerical differentiation** - Approximating derivatives using finite differences\n",
    "3. **Automatic differentiation** - Using libraries like JAX, PyTorch, or TensorFlow for gradients\n",
    "4. **Manual calculation** - For simple functions where you know the derivative formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83a3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: f(x) = x**3 + 2*x**2 + 5*x + 1\n",
      "Derivative: f'(x) = 3*x**2 + 4*x + 5\n",
      "f'(2) = 25\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Symbolic differentiation with SymPy\n",
    "import sympy as sp\n",
    "\n",
    "# Define a symbolic variable\n",
    "x = sp.Symbol('x')\n",
    "\n",
    "# Define a function\n",
    "f = x**3 + 2*x**2 + 5*x + 1\n",
    "\n",
    "# Calculate the derivative\n",
    "f_prime = sp.diff(f, x)\n",
    "\n",
    "print(f\"Function: f(x) = {f}\")\n",
    "print(f\"Derivative: f'(x) = {f_prime}\")\n",
    "\n",
    "# You can also evaluate the derivative at specific points\n",
    "x_value = 2\n",
    "derivative_at_2 = f_prime.subs(x, x_value)\n",
    "print(f\"f'(2) = {derivative_at_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3310014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical derivative at x=2: 25.000000000119368\n",
      "Analytical derivative at x=2: 25\n",
      "Error: 1.1936762689401803e-10\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Numerical differentiation (finite differences)\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Example function: f(x) = x^3 + 2x^2 + 5x + 1\"\"\"\n",
    "    return x**3 + 2*x**2 + 5*x + 1\n",
    "\n",
    "def numerical_derivative(func, x, h=1e-5):\n",
    "    \"\"\"Calculate derivative using central difference formula\"\"\"\n",
    "    return (func(x + h) - func(x - h)) / (2 * h)\n",
    "\n",
    "# Calculate derivative at x = 2\n",
    "x_point = 2\n",
    "numerical_deriv = numerical_derivative(f, x_point)\n",
    "print(f\"Numerical derivative at x=2: {numerical_deriv}\")\n",
    "\n",
    "# For comparison, the analytical derivative is 3x^2 + 4x + 5\n",
    "analytical_deriv = 3 * x_point**2 + 4 * x_point + 5\n",
    "print(f\"Analytical derivative at x=2: {analytical_deriv}\")\n",
    "print(f\"Error: {abs(numerical_deriv - analytical_deriv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "289bafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX automatic differentiation at x=2: 25.0\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Automatic differentiation with JAX\n",
    "# Note: You may need to install JAX first: pip install jax jaxlib\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    \n",
    "    def f_jax(x):\n",
    "        \"\"\"Same function using JAX\"\"\"\n",
    "        return x**3 + 2*x**2 + 5*x + 1\n",
    "    \n",
    "    # Create the derivative function\n",
    "    f_prime_jax = jax.grad(f_jax)\n",
    "    \n",
    "    # Evaluate at x = 2\n",
    "    x_val = 2.0\n",
    "    derivative_jax = f_prime_jax(x_val)\n",
    "    print(f\"JAX automatic differentiation at x=2: {derivative_jax}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"JAX not installed. You can install it with: pip install jax jaxlib\")\n",
    "    print(\"For now, showing how it would work:\")\n",
    "    print(\"import jax\")\n",
    "    print(\"f_prime = jax.grad(f)\")\n",
    "    print(\"derivative = f_prime(2.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cfeca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: f(x,y) = x**2*y + 3*x*y**2 + y**3\n",
      "∂f/∂x = 2*x*y + 3*y**2\n",
      "∂f/∂y = x**2 + 6*x*y + 3*y**2\n",
      "∂²f/∂x² = 2*y\n",
      "∂²f/∂x∂y = 2*(x + 3*y)\n"
     ]
    }
   ],
   "source": [
    "# Method 4: Partial derivatives for multivariable functions\n",
    "import sympy as sp\n",
    "\n",
    "# Define multiple variables\n",
    "x, y = sp.symbols('x y')\n",
    "\n",
    "# Define a multivariable function\n",
    "f_multi = x**2 * y + 3*x*y**2 + y**3\n",
    "\n",
    "print(f\"Function: f(x,y) = {f_multi}\")\n",
    "\n",
    "# Calculate partial derivatives\n",
    "df_dx = sp.diff(f_multi, x)  # ∂f/∂x\n",
    "df_dy = sp.diff(f_multi, y)  # ∂f/∂y\n",
    "\n",
    "print(f\"∂f/∂x = {df_dx}\")\n",
    "print(f\"∂f/∂y = {df_dy}\")\n",
    "\n",
    "# Calculate second derivatives\n",
    "d2f_dx2 = sp.diff(f_multi, x, 2)  # ∂²f/∂x²\n",
    "d2f_dxdy = sp.diff(f_multi, x, y)  # ∂²f/∂x∂y\n",
    "\n",
    "print(f\"∂²f/∂x² = {d2f_dx2}\")\n",
    "print(f\"∂²f/∂x∂y = {d2f_dxdy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f677c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cost: 0.7500\n",
      "Gradient w.r.t. w: -4.0000\n",
      "Gradient w.r.t. b: -1.0000\n",
      "\n",
      "These gradients tell us how to adjust w and b to minimize the cost!\n"
     ]
    }
   ],
   "source": [
    "# Practical Example: Derivatives for Machine Learning Cost Function\n",
    "import numpy as np\n",
    "\n",
    "def cost_function(w, b, x, y):\n",
    "    \"\"\"\n",
    "    Linear regression cost function: J = (1/2m) * sum((wx + b - y)^2)\n",
    "    \"\"\"\n",
    "    m = len(x)\n",
    "    predictions = w * x + b\n",
    "    cost = (1/(2*m)) * np.sum((predictions - y)**2)\n",
    "    return cost\n",
    "\n",
    "def cost_gradients(w, b, x, y):\n",
    "    \"\"\"\n",
    "    Analytical gradients of the cost function\n",
    "    dJ/dw = (1/m) * sum((wx + b - y) * x)\n",
    "    dJ/db = (1/m) * sum(wx + b - y)\n",
    "    \"\"\"\n",
    "    m = len(x)\n",
    "    predictions = w * x + b\n",
    "    errors = predictions - y\n",
    "    \n",
    "    dJ_dw = (1/m) * np.sum(errors * x)\n",
    "    dJ_db = (1/m) * np.sum(errors)\n",
    "    \n",
    "    return dJ_dw, dJ_db\n",
    "\n",
    "# Example data\n",
    "x_data = np.array([1, 2, 3, 4, 5])\n",
    "y_data = np.array([2, 4, 6, 8, 10])\n",
    "w_current = 1.5\n",
    "b_current = 0.5\n",
    "\n",
    "# Calculate cost and gradients\n",
    "current_cost = cost_function(w_current, b_current, x_data, y_data)\n",
    "dJ_dw, dJ_db = cost_gradients(w_current, b_current, x_data, y_data)\n",
    "\n",
    "print(f\"Current cost: {current_cost:.4f}\")\n",
    "print(f\"Gradient w.r.t. w: {dJ_dw:.4f}\")\n",
    "print(f\"Gradient w.r.t. b: {dJ_db:.4f}\")\n",
    "print(\"\\nThese gradients tell us how to adjust w and b to minimize the cost!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
